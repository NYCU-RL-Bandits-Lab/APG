APG_epoch_size: 100000000
APG_graphing_size:
- 10000000
PG_adam_epoch_size: 100000000
PG_adam_graphing_size:
- 10000000
PG_epoch_size: 100000000
PG_graphing_size:
- 10000000
PG_heavy_ball_epoch_size: 100000000
PG_heavy_ball_graphing_size:
- 10000000
V_opt: 1.0
V_opts: 1.0
action_num: 3
chunk_size: 100000
d_rho_opt: 1.0
env: /home/u7409556/APG/mdp_env/bandit_hard.yaml
eta: 0.4
fname: bandit_hard
gamma: 0.0
initial_state_distribution_dict:
  s1: 1
initial_theta_dict:
  s1:
  - 1.0
  - 3.0
  - 5.0
log_root: /work1/u7409556/APG/logs
max_iter: 100000000
optimal_policy:
- 0
random_mdp: false
reward_dict:
  s1_a1: 1.0
  s1_a2: 0.99
  s1_a3: 0.0
run_algos:
- PG
- APG
- PG_heavy_ball
- PG_adam
seed_num: 1
state_action_num:
- null
- null
state_num: 1
stochastic: false
transition_prob_dict:
  s1a1_s1: 1
  s1a2_s1: 1
  s1a3_s1: 1
