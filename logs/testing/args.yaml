APG_epoch_size: 1000
APG_graphing_size:
- 1000
PG_epoch_size: 1000
PG_graphing_size:
- 1000
V_opt: 9.999999999999996
V_opts:
- 9.999999999999996
- 9.999999999999996
action_num: 3
chunk_size: 100000
d_rho_opt:
- 0.5199999999999998
- 0.4799999999999997
env: ./mdp_env/test.yaml
eta: 0.00012499999999999992
fname: testing
gamma: 0.9
initial_state_distribution_dict:
  s1: 0.7
  s2: 0.3
initial_theta_dict:
  s1:
  - 1.0
  - 3.0
  - 5.0
  s2:
  - 1.0
  - 5.0
  - 8.0
log_root: ./logs
max_iter: 100000000
optimal_policy:
- 0
- 0
random_mdp: false
reward_dict:
  s1_a1: 1.0
  s1_a2: 0.99
  s1_a3: 0.0
  s2_a1: 1.0
  s2_a2: 0.7
  s2_a3: 0.0
run_algos:
- APG
- PG
seed_num: 1
state_action_num:
- null
- null
state_num: 2
stochastic: false
transition_prob_dict:
  s1a1_s1: 0.5
  s1a1_s2: 0.5
  s1a2_s1: 0.5
  s1a2_s2: 0.5
  s1a3_s1: 0.5
  s1a3_s2: 0.5
  s2a1_s1: 0.5
  s2a1_s2: 0.5
  s2a2_s1: 0.5
  s2a2_s2: 0.5
  s2a3_s1: 0.5
  s2a3_s2: 0.5
